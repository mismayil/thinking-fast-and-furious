{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171eccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8971f4-df3d-4c67-803c-55abc03d9d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [00:00<00:00, 2178.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from modeling import process_dataset, produce_idefics_dataset\n",
    "\n",
    "train_data_path = '/mnt/u14157_ic_nlp_001_files_nfs/nlpdata1/home/ismayilz/cs503-project/data/train/nuscenes/v1_1_train_nus_ext_converted.json'\n",
    "\n",
    "train_dataset = process_dataset(train_data_path, apply_context=\"chain\")\n",
    "train_idefics_dataset = produce_idefics_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b7a6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ismayilz/.conda/envs/cs503/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoProcessor\n",
    "from modeling import get_objects\n",
    "\n",
    "model_dir = \"HuggingFaceM4/idefics2-8b\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_dir,\n",
    "    do_image_splitting=False\n",
    ")\n",
    "\n",
    "# with open(\"./data/nuscenes/train_idefics_redcircle_vb_chain.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "from modeling import GVQADataCollator\n",
    "\n",
    "# c = GVQADataCollator(processor)\n",
    "\n",
    "with open(\"data/nuscenes/train_idefics_redcircle_vb_chain_od.json\") as f:\n",
    "    train_idefics_dataset = json.load(f)\n",
    "\n",
    "for sample in train_idefics_dataset:\n",
    "    question_text = sample[\"user_message\"][0][\"content\"][-1][\"text\"]\n",
    "    question = question_text\n",
    "    # context = None\n",
    "\n",
    "    # if \"Task:\" in question_text:\n",
    "    #     parts = question_text.split(\"Task:\")\n",
    "    #     context = parts[0].strip()\n",
    "    #     question = parts[1].strip()\n",
    "\n",
    "    question_objects = get_objects(question)\n",
    "    colors = [\"red\", \"blue\", \"black\", \"white\", \"green\", \"yellow\", \"grey\", \"orange\"]\n",
    "    assert len(question_objects) <= len(colors)\n",
    "\n",
    "# _ = c(train_idefics_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845453a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<c1,CAM_BACK,1088.3,497.5>', '<c2,CAM_BACK,864.2,468.3>', '<c3,CAM_FRONT,1043.2,82.2>', '<c1,CAM_BACK,1088.3,497.5>', '<c1,CAM_BACK,1088.3,497.5>', '<c1,CAM_BACK,1088.3,497.5>', '<c2,CAM_BACK,864.2,468.3>', '<c2,CAM_BACK,864.2,468.3>', '<c3,CAM_FRONT,1043.2,82.2>']\n",
      "{'CAM_BACK': [[1088.3, 497.5], [864.2, 468.3]], 'CAM_FRONT': [[1043.2, 82.2]]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Context:\\nQ:What are the important objects in the current scene? Those objects will be considered for the future reasoning and driving decision.\\nA:There is a brown SUV to the back of the ego vehicle, a black sedan to the back of the ego vehicle, and a green light to the front of the ego vehicle. The IDs of these objects are <c1,CAM_BACK,1088.3,497.5>, <c2,CAM_BACK,864.2,468.3>, and <c3,CAM_FRONT,1043.2,82.2>.\\nQ:What is the moving status of object <c1,CAM_BACK,1088.3,497.5>? Please select the correct answer from the following options: A. Stopped. B. Reverse parking. C. Turn left. D. Back up.\\nA:C\\nQ:What is the object <c1,CAM_BACK,1088.3,497.5>?\\nA:Brown SUV\\nQ:What is the bounding box and the category of the Brown SUV in back of the ego vehicle?\\nA:966.6,403.3,1224.1,591.7 Vehicle\\nQ:What is the center coordinate of the Brown SUV in back of the ego vehicle?\\nA:1088.3,497.5\\nQ:What is the status of the Brown SUV (<c1,CAM_BACK,1088.3,497.5>)?\\nA:Moving\\nQ:What is the object <c2,CAM_BACK,864.2,468.3>?\\nA:Black sedan\\nQ:What is the bounding box and the category of the Black sedan in back of the ego vehicle?\\nA:816.7,431.6,917.2,505.0 Vehicle\\nQ:What is the center coordinate of the Black sedan in back of the ego vehicle?\\nA:864.2,468.3\\nQ:What is the status of the Black sedan (<c2,CAM_BACK,864.2,468.3>)?\\nA:Moving\\nQ:What is the object <c3,CAM_FRONT,1043.2,82.2>?\\nA:Green light\\nQ:What is the bounding box and the category of the Green light in front of the ego vehicle?\\nA:676.4,0.0,1452.6,171.5 Traffic element\\nQ:What is the center coordinate of the Green light in front of the ego vehicle?\\nA:1043.2,82.2\\nTask:\\nWhat object should the ego vehicle notice first when the ego vehicle is getting to the next possible location? What is the state of the object that is first noticed by the ego vehicle and what action should the ego vehicle take? What object should the ego vehicle notice second when the ego vehicle is getting to the next possible location? What is the state of the object perceived by the ego vehicle as second and what action should the ego vehicle take? What object should the ego vehicle notice third? What is the state of the object perceived by the ego vehicle as third and what action should the ego vehicle take?\"\n",
    "from modeling import get_objects, objects_to_dict\n",
    "\n",
    "objects = get_objects(text)\n",
    "dict_o = objects_to_dict(objects)\n",
    "print(objects)\n",
    "print(dict_o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
